{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetection:\n",
    "    def __init__(\n",
    "        self, weights_path=\"dnn_model/yolov4.weights\", cfg_path=\"dnn_model/yolov4.cfg\"\n",
    "    ):\n",
    "        print(\"Loading Object Detection\")\n",
    "        print(\"Running opencv dnn with YOLOv4\")\n",
    "        self.nmsThreshold = 0.3\n",
    "        self.confThreshold = 0.6\n",
    "        self.image_size = 224  # Reduced for speed, change as needed\n",
    "\n",
    "        # Load Network\n",
    "        net = cv2.dnn.readNet(weights_path, cfg_path)\n",
    "\n",
    "        # Enable GPU CUDA\n",
    "        net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "        net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "        self.model = cv2.dnn_DetectionModel(net)\n",
    "\n",
    "        self.model.setInputParams(size=(self.image_size, self.image_size), scale=1 / 255)\n",
    "\n",
    "    def detect(self, frame):\n",
    "        # Detect objects, only retrieve boxes and scores\n",
    "        _, scores, boxes = self.model.detect(frame, nmsThreshold=self.nmsThreshold, confThreshold=self.confThreshold)\n",
    "        return scores, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_object(event, x, y, flags, param):\n",
    "    global tracking_object_id, selected_box, tracking_locked\n",
    "    if event == cv2.EVENT_LBUTTONDOWN and not tracking_locked:\n",
    "        frame_number = param[\"frame_number\"]\n",
    "        print(f\"Click recorded at frame {frame_number}, coordinates: ({x}, {y})\")\n",
    "\n",
    "        min_distance = float(\"inf\")\n",
    "        closest_box = None\n",
    "\n",
    "        for i, box in enumerate(param[\"boxes\"]):\n",
    "            (bx, by, bw, bh) = box\n",
    "            # Calculate the center of the box\n",
    "            box_center_x = bx + bw / 2\n",
    "            box_center_y = by + bh / 2\n",
    "            # Calculate the Euclidean distance from click point to box center\n",
    "            distance = math.sqrt((x - box_center_x) ** 2 + (y - box_center_y) ** 2)\n",
    "            # Check if this is the closest box\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_box = box\n",
    "                tracking_object_id = i\n",
    "\n",
    "        # Update selected box with the closest box found\n",
    "        if closest_box is not None:\n",
    "            selected_box = closest_box\n",
    "            tracking_locked = True  # Lock tracking to this object\n",
    "            print(f\"Selected box: {selected_box}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Object Detection\n",
      "Running opencv dnn with YOLOv4\n"
     ]
    }
   ],
   "source": [
    "# Initialize Object Detection\n",
    "od = ObjectDetection()\n",
    "cap = cv2.VideoCapture(\"los_angeles.mp4\")\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up mouse callback\n",
    "cv2.namedWindow(\"Frame\")\n",
    "# cv2.setMouseCallback(\"Frame\", select_object, param={\"frame_number\": 0, \"boxes\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize tracking variables\n",
    "tracking_object_id = None\n",
    "selected_box = None\n",
    "tracking_locked = False  # Flag to lock tracking to a selected object\n",
    "\n",
    "frame_number = 0  # Initialize frame number for tracking clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_number = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@20.848] global net_impl.cpp:178 setUpNet DNN module was not built with CUDA backend; switching to CPU\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(frame, (\u001b[38;5;241m192\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m144\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Detect objects in frame\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m scores, boxes \u001b[38;5;241m=\u001b[39m \u001b[43mod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Update mouse callback with the current frame's data\u001b[39;00m\n\u001b[1;32m     15\u001b[0m cv2\u001b[38;5;241m.\u001b[39msetMouseCallback(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m, select_object, param\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe_number\u001b[39m\u001b[38;5;124m\"\u001b[39m: frame_number, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m: boxes})\n",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m, in \u001b[0;36mObjectDetection.detect\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect\u001b[39m(\u001b[38;5;28mself\u001b[39m, frame):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Detect objects, only retrieve boxes and scores\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     _, scores, boxes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnmsThreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnmsThreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfThreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfThreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scores, boxes\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    print(f\"frame_number = {frame_number}\")\n",
    "    frame_number += 1\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (192 * 3, 144 * 3))\n",
    "\n",
    "    # Detect objects in frame\n",
    "    scores, boxes = od.detect(frame)\n",
    "\n",
    "    # Update mouse callback with the current frame's data\n",
    "    cv2.setMouseCallback(\"Frame\", select_object, param={\"frame_number\": frame_number, \"boxes\": boxes})\n",
    "\n",
    "    # Track the selected box if one has been chosen and locked\n",
    "    if selected_box is not None:\n",
    "        min_distance = float(\"inf\")\n",
    "        closest_box = None\n",
    "\n",
    "        # Find the box in the current frame closest to the last known position\n",
    "        (prev_x, prev_y, prev_w, prev_h) = selected_box\n",
    "        prev_center_x = prev_x + prev_w / 2\n",
    "        prev_center_y = prev_y + prev_h / 2\n",
    "\n",
    "        for box in boxes:\n",
    "            (bx, by, bw, bh) = box\n",
    "            box_center_x = bx + bw / 2\n",
    "            box_center_y = by + bh / 2\n",
    "            distance = math.sqrt(\n",
    "                (prev_center_x - box_center_x) ** 2\n",
    "                + (prev_center_y - box_center_y) ** 2\n",
    "            )\n",
    "\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_box = box\n",
    "\n",
    "        # Update the selected box with the closest matching box from the detections\n",
    "        if closest_box is not None:\n",
    "            selected_box = closest_box\n",
    "\n",
    "        # Draw the updated selected box\n",
    "        (x, y, w, h) = selected_box\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "    else:\n",
    "        print(\"No box selected\")\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    # Increment the frame number for click tracking\n",
    "\n",
    "    # key = cv2.waitKey(1)\n",
    "    # # Press 'r' to reset selection and unlock tracking\n",
    "    # if key == ord(\"r\"):\n",
    "    #     tracking_locked = False\n",
    "    #     selected_box = None\n",
    "    #     print(\"Tracking reset\")\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
